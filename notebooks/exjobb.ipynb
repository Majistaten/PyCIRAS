{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbe30f4-2377-4ca8-91e7-f08cf80a9f4b",
   "metadata": {},
   "source": [
    "# Exjobb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65ffc3-c263-470a-911c-0ca9ce6a46d6",
   "metadata": {},
   "source": [
    "## TODO General\n",
    "\n",
    "- [ ] Boka möte med sergio innan V.16, han är borta på ICSE hela den veckan\n",
    "- [ ] Testa Codescene, vad kan vi få fram av det? Hur kan vi använda?\n",
    "\n",
    "## TODO Technical\n",
    "\n",
    "- [x] Refactor\n",
    "- [ ] Kommer state i en notebook att versionshanteras eller inte? Undersök\n",
    "- [x] Fyll i alla repos i sheets \"Repos som inte crashar\"\n",
    "- [x] Testkör alla repos, se om vi hittar några som kraschar - kolla om det beror på stört dataset eller enorma commits\n",
    "- [x] Ta bort dessa och anteckna vilka\n",
    "- [ ] Testa alla repos och se så de inte är helt galna, sen testa kör alla tillsammans och kolla JSON filerna inte blir för stora etc\n",
    "- [x] Testa stäng av JSON uppdateringen och använd endast CSV - då kanske det funkar med grisrepos- skriv oftare så inte dicts blir för stora?\n",
    "- [x] Måste ha progress på skrivningarna, är helt unresponsive vid stora skrivningar\n",
    "- [x] Forcera garbage collection - en ide för att minska prestandaätningen\n",
    "- [ ] Bygg in ett sätt att exkludera directorys i \"Get python files from repo\", så vi inte hämtar in massa testdata och skit, se till att den är recursive så den hittar allt annat relevant\n",
    "\n",
    "\n",
    "#### Pylint\n",
    "\n",
    "Pylint inställningar\n",
    "\n",
    "- [x] Måste ignorera venv, /out och liknande mappar med pythonkod som inte hör till repot.\n",
    "- [x] Fixa alla bra plugins\n",
    "- [x] Fixa bästat inställningen på j= så vi får resultat närmast sanningen\n",
    "- [ ] Skumma igenom repos för att hitta uppenbara directorys som ska exkluderas för att inte korruptera lint och testdatan\n",
    "        \n",
    "#### Multiprocessing\n",
    "\n",
    "- [x] Fixa progressbars\n",
    "- [x] Fixa mutex på läs/skrivningar till fil\n",
    "- [x] Progressbarsen ska ha repots namn hela tiden så man ser vilken den sysslar med och i vilket steg\n",
    "\n",
    "#### Testrepos\n",
    "- TDD-hangman - 2 min 25 sek\n",
    "- sadl - 2 min\n",
    "- Conala baseline - 35 sek\n",
    "- amalfi - 3 sek\n",
    "- Tailor - 39 sek\n",
    "\n",
    "estimerad total : 5.7min parallellt\n",
    "\n",
    "Executiontime paralell: 3:48\n",
    "Executiontime sekventiell: 6:22\n",
    "\n",
    "#### Pyciras settings\n",
    "- Samma ordning i repos.txt\n",
    "- repo cloner: chunk_size=repos, multiprocessing=true\n",
    "- run_mining: chunk_size=1 multprocessing=false, persist-repos=False, alla mining=true\n",
    "\n",
    "## TODO Thesis\n",
    "\n",
    "- [ ] Mine selected repos\n",
    "\n",
    "#### Literature\n",
    "\n",
    "- [ ] Gör en query-bot med research\n",
    "- [ ] Leta model dokument som beskriver\n",
    "\n",
    "#### Writing\n",
    "\n",
    "- [ ] Hitta ett bra sätt att visa upp alla repos vi ska analysera liknande berras thesis\n",
    "- [ ] \n",
    "\n",
    "#### Exclusion Criteria\n",
    "\n",
    "- [ ] Define all exclusion criteria\n",
    "\n",
    "- Below X Commits\n",
    "- Exclude repos with big dataset/problematic for analysis\n",
    "- Has Python as main language\n",
    "\n",
    "* https://github.com/dockerizeme/dockerizeme (För många pythonfiler per commit)\n",
    "* https://github.com/ucd-plse/On-the-Reproducibility (Innehåller enorma commits, störda datasets) över 20 gig stort\n",
    "* https://github.com/DroidTest/TimeMachine (INnehåller enorma binaries och APKer) Extremt stor, lint data 5/101 efter 22 minuter, 77261 messages, 106 filer, 90 moduler vad nu de är. Tog 8 timmar. Kan minas för skoj, men kanske inte\n",
    "* https://github.com/tjusenchen/StoryDroid (Stor, lint data 44/86 efter 36 minuter, 70/86 efter 2:20) Pylint når maximum recursion depth\n",
    "* https://github.com/Software-Aurora-Lab/DoppelTest (Extremt seg, tog 15min och hann inte med lint på första commitet)\n",
    "* https://github.com/zysszy/CAT (Orsakar SIGKILL och fyller swapfilen till MAX på linux när man kör pydriller, innehåller extrema mängder text)\n",
    "\n",
    "#### RQ1 - Descriptive/Exploration of repo stats\n",
    "\n",
    "Per Repo Data - Plotting/Graphing/Visualization + writing. Vad ska vi visualisera? Vad bör vi visa i rapporten? Hur få det att se bra ut med 100 repos?\n",
    "\n",
    "- [ ] Kolla upp cluster classification - hur kan vi nyttja det? \n",
    "\n",
    "3 olika sektioner:\n",
    "\n",
    "- Git data\n",
    "    - Stars\n",
    "- Lint data\n",
    "    - [ ] Hitta en klassificering på hur datan ska presenteras och kategoriseras \n",
    "    - Stats\n",
    " - Test data\n",
    "    - ?  \n",
    "\n",
    "#### RQ2 - Correlation Analysis of metrics compared to stargazers\n",
    "\n",
    "Tidsserie-data per commit/date\n",
    "\n",
    "- [ ] \"Group Correlation\", leta rätt på nåt lämpligt sätt att mäta inom ett repo, och få ut nåt genomsnitt eller liknande\n",
    "- Dynamiskt analysera alla repos var för sig med en stor funktion, samla ihop all data i en datastruktur och plocka fram nåt genomsnitt från det?\n",
    "- Joina ihop alla repos och skjuta av en correlation analysis på alla?\n",
    "- Make an \"as-of\" join on date, vad är rimligt att ha för tolerans i diff på datum?\n",
    "- Vad ska vi visualisera? Vad bör vi visa i rapporten?\n",
    "\n",
    "Per-repo data\n",
    "\n",
    "- Correlation analysis på detta också fast mellan repos?\n",
    "\n",
    "#### Methodology RQ1\n",
    "\n",
    "#### Methodology RQ2\n",
    "\n",
    "- Make a notebook\n",
    "- Clone all repos in parallel\n",
    "- execute all mining in sequentially, remove each repo after analysis for storage\n",
    "- load csvs to pandas\n",
    "- as-of join together all metrics on date with some tolerance, add stargazers with filtering based on repo creation date (set nan for values before it was created)  \n",
    "- visualize\n",
    "- process and calculate statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
