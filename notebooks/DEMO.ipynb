{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5c7a04-0429-4993-84d0-daa1866cbd1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Demonstration of PyCIRAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f1ff7-a6e3-4ddc-b165-c2b40d3ef0ff",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a0159-3cd5-484a-84bd-933b258f3918",
   "metadata": {},
   "source": [
    "### Prepare base imports\n",
    "Import the setup script to build the environment and pyciras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c76d33-fe0f-4667-ac89-5120e2b4e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup_notebook_environment\n",
    "import pyciras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e5513c-1cea-4862-b1b9-758a6e9f7fa0",
   "metadata": {},
   "source": [
    "### Mining - Code Quality, Git metrics, Unit-Testing, Stargazers data\n",
    "\n",
    "The user can specify a list of git repos they want to analyze directly in the notebook, or in the default **/repos.txt** file.\n",
    "\n",
    "For long-running analysis, we support **ntfy** push notifications, so you can leave it running and get notified when completed. This requires modifications in `.env` and `utility/config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abdca14-212e-4058-9fbc-c62f4f1fe96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = ['https://github.com/SamuelThand/TDD-Hangman',\n",
    "         'https://github.com/coinse/sadl',\n",
    "         'https://github.com/zhangj111/astnn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fda995-1fc9-4369-8ae3-7565572175db",
   "metadata": {},
   "source": [
    "#### Clone Repositories\n",
    "You can clone the repositories in advance to ensure that all repositories can be accessed before executing a long mining process. However, this is not needed as `pyciras.run_mining()` will clone the currently mined repository if not found.\n",
    "\n",
    "The function `run_repo_cloner()` clones all repositories to the folder specified in `utility/config.py`. The parameters are listed below:\n",
    "- **repo_urls**: List of repository URLs to clone. If None, the list is loaded from `repos.txt`.\n",
    "- **chunk_size**: Number of repositories to clone in each operation chunk. Defaults to 1.\n",
    "- **multiprocessing**: Flag to enable or disable multiprocessing during cloning. Defaults to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e6e14-e063-43a8-b598-f5a7d4b8d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyciras.run_repo_cloner(repo_urls=repos,  # replace with 'None' to use repos.txt\n",
    "                        chunk_size=100,\n",
    "                        multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b10abb-d3ac-462b-877b-5dae174bc18e",
   "metadata": {},
   "source": [
    "#### Mine the Repositories\n",
    "Start the mining process to gather data. You can change content of `utility/config.py` to save the data in different formats. If you mine large amount of data, do not use JSON as it will create enormous files that may fill up you RAM.\n",
    "\n",
    "The function `run_mining()` will mine the aspects specified in the parameters listed below:\n",
    "- **repo_urls**: A list of repository URLs to be mined. If None, URLs will be loaded from `repos.txt`.\n",
    "- **chunk_size**: The number of repositories to process in each chunk. Defaults to 1.\n",
    "- **multiprocessing**: Enables or disables multiprocessing for the mining operations. Defaults to False.\n",
    "- **persist_repos**: If True, cloned repositories will be persisted in a local directory. Defaults to True.\n",
    "- **stargazers**: If True, information about stargazers will be collected for each repository. Defaults to True.\n",
    "- **metadata**: Enable or disable the metadata analysis. Defaults to True.\n",
    "- **lint**: Enables or disables linting analysis. Defaults to True.\n",
    "- **test**: Enables or disables testing analysis. Defaults to True.\n",
    "- **git**: Enables or disables Git history analysis. Defaults to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019ca45-21db-4d5e-857f-1f639ba80ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyciras.run_mining(repo_urls=repos,  # replace with 'None' to use repos.txt\n",
    "                   chunk_size=1,\n",
    "                   multiprocessing=False,\n",
    "                   persist_repos=False,\n",
    "                   stargazers=True,\n",
    "                   metadata=True,\n",
    "                   test=True,\n",
    "                   git=True,\n",
    "                   lint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c85d95-bc62-447e-9f78-f087b4743596",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "Lets say we are interested in visualizing DMM and doing a correlation analysis with the amount of stars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f6b19-3ae8-48da-b74f-23fb1165f9d1",
   "metadata": {},
   "source": [
    "### Load and display the git CSV\n",
    "Load the csv to a dataframe and visualize the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ad0bc-720d-467c-a32f-1e9faf039d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4ecb06-72a0-4e94-b7a2-f76912d3098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_df = pd.read_csv('../out/data/<CHANGE ME>/git.csv')\n",
    "display(git_df.head())\n",
    "display(git_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7bcc1d-0661-4644-b8f9-e9b673f35454",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('../out/data/<CHANGE ME>/metadata.csv')\n",
    "display(metadata_df.head())\n",
    "display(git_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd1c2a-cbce-4a1d-afd3-88ec687cddf9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Display the data in a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c7cdb-b456-4635-aaa5-8ea38c726ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract data\n",
    "average_dmm_method_lines_of_code = git_df['average_dmm_method_lines_of_code']\n",
    "average_dmm_method_cyclomatic_complexity = git_df['average_dmm_method_cyclomatic_complexity']\n",
    "average_dmm_method_number_of_parameters = git_df['average_dmm_method_number_of_parameters']\n",
    "\n",
    "# Step 2: Combine into a single DataFrame\n",
    "aggregated_data = pd.DataFrame({\n",
    "    'Unit Size': average_dmm_method_lines_of_code,\n",
    "    'Unit Complexity': average_dmm_method_cyclomatic_complexity,\n",
    "    'Unit Interfacing': average_dmm_method_number_of_parameters\n",
    "})\n",
    "\n",
    "# Step 3: Create a boxplot using seaborn\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.boxplot(data=aggregated_data)\n",
    "\n",
    "plt.title('DMM Scores In Artifacts')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d2034f-9b70-4a09-8712-876bcdb53f9e",
   "metadata": {},
   "source": [
    "### Perform correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5461fa-f6b3-4f4d-ab87-7ecfbab5cb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var1 = 'average_dmm_method_cyclomatic_complexity'\n",
    "var2 = 'stargazerCount'\n",
    "\n",
    "# Load and merge datasets\n",
    "dataframe = pd.merge(git_df, metadata_df, on='repo')[[var1, var2]]\n",
    "display(dataframe.head())\n",
    "display(dataframe.describe())\n",
    "\n",
    "# Shapiro-Wilk Test - Normal distribution of data\n",
    "shapiro_test_var1 = stats.shapiro(dataframe[var1].dropna())\n",
    "shapiro_test_var2 = stats.shapiro(dataframe[var2].dropna())\n",
    "display(f\"Shapiro-Wilk Test for {var1}: Statistic={shapiro_test_var1.statistic}, P-value={shapiro_test_var1.pvalue}\")\n",
    "display(f\"Shapiro-Wilk Test for {var2}: Statistic={shapiro_test_var2.statistic}, P-value={shapiro_test_var2.pvalue}\")\n",
    "\n",
    "# Decide on the correlation method based on normality test\n",
    "if shapiro_test_var1.pvalue > 0.05 and shapiro_test_var2.pvalue > 0.05:\n",
    "    # If data is normally distributed, use Pearson's correlation\n",
    "    pearson_corr = dataframe[[var1, var2]].corr(method='pearson')\n",
    "    correlation = pearson_corr.iloc[0, 1]\n",
    "    p_value = stats.pearsonr(dataframe[var1].dropna(), dataframe[var2].dropna())[1]\n",
    "    method_used = 'Pearson'\n",
    "    print(\"Pearson's correlation matrix:\\n\", pearson_corr)\n",
    "    print(\"Pearson's p-value:\", pearson_corr)\n",
    "else:\n",
    "    # If data is not normally distributed, use Spearman's correlation\n",
    "    spearman_corr, p_value = stats.spearmanr(dataframe[var1].dropna(), dataframe[var2].dropna())\n",
    "    correlation = spearman_corr\n",
    "    method_used = 'Spearman'\n",
    "    print(\"Spearman's correlation coefficient:\", spearman_corr)\n",
    "    print(\"Spearman's p-value:\", p_value)\n",
    "\n",
    "# Interpretation and reporting of results\n",
    "alpha = 0.05\n",
    "correlation_strength = 'no'\n",
    "if abs(correlation) > 0.7:\n",
    "    correlation_strength = 'strong'\n",
    "elif abs(correlation) > 0.3:\n",
    "    correlation_strength = 'moderate'\n",
    "elif abs(correlation) > 0.1:\n",
    "    correlation_strength = 'weak'\n",
    "\n",
    "correlation_type = 'positive' if correlation > 0 else 'negative'\n",
    "significance = 'statistically significant' if p_value < alpha else 'not statistically significant'\n",
    "\n",
    "report = (f\"There is a {correlation_strength} {correlation_type} correlation between {var1} and {var2} \"\n",
    "          f\"using {method_used} method. The correlation coefficient is {correlation:.3f}. \"\n",
    "          f\"The p-value = {p_value:.3e} which is {'smaller' if p_value < alpha else 'greater'} than the \"\n",
    "          f\"significance level (alpha) of {alpha}. The relationship is {significance}.\")\n",
    "\n",
    "display(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
