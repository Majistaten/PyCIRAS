{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbe30f4-2377-4ca8-91e7-f08cf80a9f4b",
   "metadata": {},
   "source": [
    "# Exjobb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65ffc3-c263-470a-911c-0ca9ce6a46d6",
   "metadata": {},
   "source": [
    "### TODO JUST NU\n",
    "\n",
    "1. Fyll i alla repos i sheets \"Repos som inte crashar\"\n",
    "2. Mine metadata - kolla vilka som innehåller python som primärt språk.\n",
    "3. Testkör alla repos, se om vi hittar några som kraschar - kolla om det beror på stört dataset eller enorma commits\n",
    "4. Ta bort dessa och anteckna vilka\n",
    "5. Få in storlek på största commit via metadata metoden?\n",
    "6. Testa alla repos och se så de inte är helt galna, sen testa kör alla tillsammans och kolla så JSON filerna inte blir för stora etc\n",
    "7. Testa stäng av JSON uppdateringen och använd endast CSV - då kanske det funkar med grisrepos- skriv oftare så inte dicts blir för stora?\n",
    "8. JSON-filerna blir MB/GB stora - CSV bara KB. Slutsats -> ta bort JSON filer\n",
    "9. Måste ha progress på skrivningarna, är helt unresponsive vid stora skrivningar\n",
    "10. Forcera garbage collection - en ide för att minska prestandaätningen\n",
    "11. 4 cores i pylint hjälper mkt? OBS - GER DRASTISKT OLIKA RESULTAT\n",
    "\n",
    "Borttagna repos:\n",
    "* https://github.com/dockerizeme/dockerizeme (För många pythonfiler per commit)\n",
    "* https://github.com/ucd-plse/On-the-Reproducibility (Innehåller enorma commits, störda datasets) över 20 gig stort\n",
    "* https://github.com/DroidTest/TimeMachine (INnehåller enorma binaries och APKer) Extremt stor, lint data 5/101 efter 22 minuter, 77261 messages, 106 filer, 90 moduler vad nu de är. Tog 8 timmar. Kan minas för skoj, men kanske inte\n",
    "* https://github.com/tjusenchen/StoryDroid (Stor, lint data 44/86 efter 36 minuter, 70/86 efter 2:20) Pylint når maximum recursion depth\n",
    "* https://github.com/Software-Aurora-Lab/DoppelTest (Extremt seg, tog 15min och hann inte med lint på första commitet)\n",
    "* https://github.com/zysszy/CAT (Orsakar SIGKILL och fyller swapfilen till MAX på linux när man kör pydriller, innehåller extrema mängder text)\n",
    "\n",
    "### Anomalier\n",
    "* PYCG kör unittest men det kommer inte med\n",
    "\n",
    "### Pylint debug\n",
    "\n",
    "Verkar inte vara orent git state, provat med \n",
    "\n",
    "        repo.git.reset('--hard')\n",
    "        repo.git.clean('-fdx')\n",
    "\n",
    "DET ÄR CACHEN SOM ÄR PROBLEMET, rensar man cachen efter varje körning blir resultatet detsamma.\n",
    "\n",
    "varför? Var ligger cachen? \n",
    "\n",
    "--recursive=y ger också samma cache problem\n",
    "\n",
    "CACHE FIXAD.\n",
    "\n",
    "Pylint inställningar\n",
    "\n",
    "- Måste ignorera venv, /out och liknande mappar med pythonkod som inte hör till repot.\n",
    "- Flytta in cache i projektet så man har kontroll över den\n",
    "- Fixa alla bra plugins\n",
    "- Fixa bästat inställningen på j= så vi får resultat närmast sanningen\n",
    "- \n",
    "        \n",
    "### Multiprocessing\n",
    "\n",
    "- Fixa progressbars (på g)\n",
    "- Fixa mutex på läs/skrivningar till fil\n",
    "- Progressbarsen ska ha repots namn hela tiden så man ser vilken den sysslar med och i vilket steg\n",
    "\n",
    "- \n",
    "#### Testrepos\n",
    "- TDD-hangman - 2 min 25 sek\n",
    "- sadl - 2 min\n",
    "- Conala baseline - 35 sek\n",
    "- amalfi - 3 sek\n",
    "- Tailor - 39 sek\n",
    "\n",
    "estimerad total : 5.7min parallellt\n",
    "\n",
    "Executiontime paralell: 3:48\n",
    "Executiontime sekventiell: 6:22\n",
    "\n",
    "#### Försök 1\n",
    "chunk: 3, locks och parallelism=true med jobs=2. Korrekt rader och ordning, stor diff på .by.msg - pga pylint? Endast antal messages skiljer\n",
    "JSON-filerna blev i olika ordning och de olika messages. Repos kördes i olika ordning\n",
    "https://www.textcompare.org/csv/compare/?id=65fdb2cd7020d163bdbe590f\n",
    "\n",
    "#### Försök 2\n",
    "chunk: 3, locks och parallelism=true med jobs=2. Samma ordning som sekvensiell i repos.txt. Diffade också med massa .by.msg\n",
    "JSON-filerna blev i olika ordning\n",
    "https://www.textcompare.org/csv/compare/?id=65fdb6f8c48d8a6c3408acc3\n",
    "\n",
    "#### Försök 3\n",
    "Exakt samma inställningar som försök 2, provar att köra igen för att se om det blir samma resultat med exakt samma inställningar\n",
    "\n",
    "#### Försök 4\n",
    "Testa utan git reset hard och git clean\n",
    "\n",
    "#### Försök 5 \n",
    "Testa att köra två sekvensiella körningar och kolla om rawfilerna diffar med varandra vid något tillfälle\n",
    "\n",
    "\n",
    "#### Slutsats:\n",
    "Det diffar i RAW-filerna, det är Pylint som inte ger samma resultat om man kör flera processer samtidigt. Dock är alla stats som global note osv lika.\n",
    "\n",
    "Verkar som att Pylint kör filerna i olika ordning beroende på körning, vilket resulterar i olika messages som är kontextberoende av andra filer\n",
    "\n",
    "- #### Setup för maximum reproducibility\n",
    "- Samma ordning i repos.txt\n",
    "- Rensa pylint cache\n",
    "\n",
    "### TODO \n",
    "\n",
    "- verkar bli nån bugg när man kört flera jobs i pylint, ibland fastnar typ git eller nåt \n",
    "\n",
    "- Fundera kring hur vi ska genomföra analys 1\n",
    "    -  Dynamiskt analysera alla repos var för sig med en stor funktion, samla ihop all data i en datastruktur och plocka fram nåt genomsnitt från det?\n",
    "    -  Joina ihop alla repos och skjuta av en correlation analysis på alla?\n",
    "    -  Vad ska vi visualisera? Vad bör vi visa i rapporten?\n",
    "\n",
    "- Analys 2? Genomföra? Onödigt?\n",
    "\n",
    "#### Boka möte med sergio - få igång hans tankeprocess och involvera honom\n",
    "- Hur ska vi göra exjobbet? Börja med experimentet, skriva resultatsektionen, sen alla andra sektioner utifrån det? \"Inifrån och ut\"\n",
    "- Börja med introduktion, skriva uppifrån och ner?\n",
    "- Demonstrera programmet och visa vilken data vi får ut och hur den är formatterad\n",
    "- Hur vi ska exakt definiera kriterier för urval, hur är det relevant att göra correlationsanalysen med \"as of join\", hur stor tolerans?\n",
    "- Fråga om reuse från proposal\n",
    "- Se sergios video först\n",
    "- Maila Sergio\n",
    "\n",
    "Exkludera repos med extremt många commits, extremt många pythonfiler, extremt stor size etc\n",
    "\n",
    "### Exjobbet\n",
    "- Gör en koncentrerad söknings effort med keywords, söksträngar, hitta allt relevant arbete.\n",
    "- Gör en consistent metod för att skriva ut kommentarer i papers, t.ex att man skriver kort var varje highlighting berör\n",
    "- Skapa en ChatGPT bot utifrån alla reseach papers.\n",
    "- Läs om Latex/History feature från kursmaterialet\n",
    "- Gör tidsplan, fyll in i dokumentet\n",
    "\n",
    "### Programmet\n",
    "- Koppla ihop project lifespan med stargazers för att fylla i NaN där värdena inte är relevanta (Projekt som inte var publicerade / inte fanns ännu)\n",
    "- Refaktorera färdigt\n",
    "- Repos som crashar\n",
    "- https://github.com/ucd-plse/On-the-Reproducibility (Förmodligen pga dataset med massa sjuka logfiler)\n",
    "- Provkör med alla moduler enskilt och kolla minnet. Pydriller som inte har memory limit\n",
    "\n",
    "### Experimentet\n",
    "- Ladda ner alla repos sekventiellt med remove = true och utför mining på dom, ladda inte om notebooken utan fortsätt sedan och gör hela experimentet i samma directory\n",
    "- Gruppera ihop repos till olika körningar, irrellevant att kolla testing på vissa/stars på vissa etc\n",
    "- Gör en körning och hämta metadata på alla repos, använd för sorteringen och kriterier.\n",
    "- Kommer state i en notebook att versionshanteras eller inte? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d52093-1b34-4574-a22b-19c38753146b",
   "metadata": {},
   "source": [
    "Analysera varje repository var för sig:\n",
    "\n",
    "Börja vid datumet för första commit och gör en serie med rader:\n",
    "\n",
    "* Col1: Datum, Col2: Pylint global note, Col3: Unit Testing (vilken typ av värde), Col4.. : Metric X, ColN: Stargazers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a070b9e-e8d5-46d5-9c9b-a7c4d724baf3",
   "metadata": {},
   "source": [
    "## Analys 1 - Repos analysera för sig, med koppling mellan metrics och popularity\n",
    "\n",
    "### Pylint\n",
    "1 CSV per repo. Rad: [Datum, Global Note, Metrics...] - det borde vara bra, borde gå att joina ihop på datum från en annan CSV för t.ex stargazers\n",
    "\n",
    "plugins?\n",
    "\n",
    "### Stargazers\n",
    "1 CSV för alla repos. Rad: [Datum, (Header=Repo Cell=Stars)]. Datum flödar i Y led, en kolumn som representerar ett repo borde kunna hämtas lätt för att läggas in i analysdokument.\n",
    "\n",
    "### Unit testing\n",
    "....\n",
    "\n",
    "Någon slags correlation/causality analys på dessa inom varje repo, och sen slå ihop genomsnitt - eller göra en fet analys från en fet csv?\n",
    "\n",
    "\n",
    "Göra en AS-OF join på alla [datum/värde] från stargazers, pylint, unit testing med en viss tolerans och sen kolla korrelation mellan metric och stargazers\n",
    "\n",
    "\n",
    "## Analys 2 - Analysera alla repos popularitet över tid, kolla när unittesting/requirements.txt etc dyker upp - finns det samband?\n",
    "\n",
    "\"Såhär populära är repos med unittesting i snitt, såhär populära är dom utan\"\n",
    "\"Popularitet och antal commits över tid.. etc\"\n",
    "\n",
    "### Pydriller\n",
    "1 CSV för alla repos. Rad: [Repo, Metrics.. ] - metrics är inte tidsberoende data, utan genomsnitt för ett helt repo och en hel livstidscykel. Kan jämföras direkt mellan repos i formatet det ligger, vilket är bra. Lägg på stargazers JUST NU, som en kolumn, och jämför med datan.\n",
    "\n",
    "### Unittesting\n",
    "\n",
    "csv format..\n",
    "\n",
    "Analysera alla repos popularity över tid, och se om det finns ett samband att unit testing har\n",
    "börjat förekomma i många repos desto populärare de har blivit. Representera med att tidpunkterna för analysen har olika färger. Svart = ingen unit testing, Grön = använder unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619d3a3-34ab-49fa-8f48-e04d3a793221",
   "metadata": {},
   "source": [
    "## Joina ihop data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd4a52-4d8c-4338-b36e-4434cd09be78",
   "metadata": {},
   "source": [
    "Bygg en lista med Rad: [datum] som är de datum som gäller, typ slå samman datumkolumnerna från alla analyser och normalisera. \n",
    "\n",
    "Lägg på kolumner med metrics från från pylint, och andra metrics, och stargazers.\n",
    "\n",
    "Jämför direkt\n",
    "\n",
    "Datum: <--- commit historiken. (start, slut)\n",
    "\n",
    "Baserat på dessa datum -> hämta ut star historian\n",
    "\n",
    "Filtrera bort star history från utanför projektets lifespan -> baserat på lifespan CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
