{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbe30f4-2377-4ca8-91e7-f08cf80a9f4b",
   "metadata": {},
   "source": [
    "# EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65ffc3-c263-470a-911c-0ca9ce6a46d6",
   "metadata": {},
   "source": [
    "### TODO \n",
    "\n",
    "- Fundera kring hur vi ska genomföra analys 1\n",
    "    -  Dynamiskt analysera alla repos var för sig med en stor funktion, samla ihop all data i en datastruktur och plocka fram nåt genomsnitt från det?\n",
    "    -  Joina ihop alla repos och skjuta av en correlation analysis på alla?\n",
    "    -  Vad ska vi visualisera? Vad bör vi visa i rapporten?\n",
    "\n",
    "- Analys 2? Genomföra? Onödigt?\n",
    "\n",
    "#### Boka möte med sergio - få igång hans tankeprocess och involvera honom\n",
    "- Hur ska vi göra exjobbet? Börja med experimentet, skriva resultatsektionen, sen alla andra sektioner utifrån det? \"Inifrån och ut\"\n",
    "- Börja med introduktion, skriva uppifrån och ner?\n",
    "- Demonstrera programmet och visa vilken data vi får ut och hur den är formatterad\n",
    "- Hur vi ska exakt definiera kriterier för urval, hur är det relevant att göra correlationsanalysen med \"as of join\", hur stor tolerans?\n",
    "- Fråga om reuse från proposal\n",
    "\n",
    "Exkludera repos med extremt många commits, extremt många pythonfiler, extremt stor size etc\n",
    "\n",
    "### Exjobbet\n",
    "- Gör en koncentrerad söknings effort med keywords, söksträngar, hitta allt relevant arbete.\n",
    "- Gör en consistent metod för att skriva ut kommentarer i papers, t.ex att man skriver kort var varje highlighting berör\n",
    "- Skapa en ChatGPT bot utifrån alla reseach papers.\n",
    "\n",
    "### Programmet\n",
    "- Koppla ihop project lifespan med stargazers för att fylla i NaN där värdena inte är relevanta (Projekt som inte var publicerade / inte fanns ännu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d52093-1b34-4574-a22b-19c38753146b",
   "metadata": {},
   "source": [
    "Analysera varje repository var för sig:\n",
    "\n",
    "Börja vid datumet för första commit och gör en serie med rader:\n",
    "\n",
    "* Col1: Datum, Col2: Pylint global note, Col3: Unit Testing (vilken typ av värde), Col4.. : Metric X, ColN: Stargazers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a070b9e-e8d5-46d5-9c9b-a7c4d724baf3",
   "metadata": {},
   "source": [
    "## Analys 1 - Repos analysera för sig, med koppling mellan metrics och popularity\n",
    "\n",
    "### Pylint\n",
    "1 CSV per repo. Rad: [Datum, Global Note, Metrics...] - det borde vara bra, borde gå att joina ihop på datum från en annan CSV för t.ex stargazers\n",
    "\n",
    "plugins?\n",
    "\n",
    "### Stargazers\n",
    "1 CSV för alla repos. Rad: [Datum, (Header=Repo Cell=Stars)]. Datum flödar i Y led, en kolumn som representerar ett repo borde kunna hämtas lätt för att läggas in i analysdokument.\n",
    "\n",
    "### Unit testing\n",
    "....\n",
    "\n",
    "Någon slags correlation/causality analys på dessa inom varje repo, och sen slå ihop genomsnitt - eller göra en fet analys från en fet csv?\n",
    "\n",
    "\n",
    "Göra en AS-OF join på alla [datum/värde] från stargazers, pylint, unit testing med en viss tolerans och sen kolla korrelation mellan metric och stargazers\n",
    "\n",
    "\n",
    "## Analys 2 - Analysera alla repos popularitet över tid, kolla när unittesting/requirements.txt etc dyker upp - finns det samband?\n",
    "\n",
    "\"Såhär populära är repos med unittesting i snitt, såhär populära är dom utan\"\n",
    "\"Popularitet och antal commits över tid.. etc\"\n",
    "\n",
    "### Pydriller\n",
    "1 CSV för alla repos. Rad: [Repo, Metrics.. ] - metrics är inte tidsberoende data, utan genomsnitt för ett helt repo och en hel livstidscykel. Kan jämföras direkt mellan repos i formatet det ligger, vilket är bra. Lägg på stargazers JUST NU, som en kolumn, och jämför med datan.\n",
    "\n",
    "### Unittesting\n",
    "\n",
    "csv format..\n",
    "\n",
    "Analysera alla repos popularity över tid, och se om det finns ett samband att unit testing har\n",
    "börjat förekomma i många repos desto populärare de har blivit. Representera med att tidpunkterna för analysen har olika färger. Svart = ingen unit testing, Grön = använder unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619d3a3-34ab-49fa-8f48-e04d3a793221",
   "metadata": {},
   "source": [
    "## Joina ihop data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd4a52-4d8c-4338-b36e-4434cd09be78",
   "metadata": {},
   "source": [
    "Bygg en lista med Rad: [datum] som är de datum som gäller, typ slå samman datumkolumnerna från alla analyser och normalisera. \n",
    "\n",
    "Lägg på kolumner med metrics från från pylint, och andra metrics, och stargazers.\n",
    "\n",
    "Jämför direkt\n",
    "\n",
    "Datum: <--- commit historiken. (start, slut)\n",
    "\n",
    "Baserat på dessa datum -> hämta ut star historian\n",
    "\n",
    "Filtrera bort star history från utanför projektets lifespan -> baserat på lifespan CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
